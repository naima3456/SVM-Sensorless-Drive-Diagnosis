{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4c41c1",
   "metadata": {},
   "source": [
    "# SVM\n",
    "L'algorithme SVM, ou Support Vector Machine, est une technique d'apprentissage supervisé utilisée pour résoudre des problèmes de classification et de régression. L'idée principale de l'algorithme SVM est de trouver une frontière, appelée hyperplan, qui sépare au mieux les différentes classes dans l'espace des données. Cela implique la maximisation de la marge, c'est-à-dire la distance entre l'hyperplan et les points de données les plus proches de chaque classe. Ces points, appelés vecteurs de support, sont essentiels pour déterminer la position et l'orientation de l'hyperplan.\n",
    "### Séparation des classes de données\n",
    "On distingue deux cas de figure: \n",
    "- Données linéairement séparables: Si les classes de données sont linéairement séparables, c'est-à-dire qu'il existe un hyperplan qui peut parfaitement séparer les différentes classes.\n",
    "- Données non linéairement séparables: Si les classes de données ne peuvent pas être séparées de manière linéaire, l'algorithme SVM utilise des techniques de noyau pour les transformer dans un espace de grande dimension où elles peuvent être séparées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23253c3",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fee4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5cd6f",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2777e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from url\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00325/Sensorless_drive_diagnosis.txt'\n",
    "data = pd.read_csv(url, header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce08ee77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__dataframe__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_add_numeric_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_append',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_box_col_values',\n",
       " '_can_fast_transpose',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_combine_frame',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_data',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_dispatch_frame_op',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_from_arrays',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_column_array',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_copy',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_iset_item',\n",
       " '_iset_item_mgr',\n",
       " '_iset_not_inplace',\n",
       " '_item_cache',\n",
       " '_iter_column_arrays',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_needs_reindex_multi',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reduce_axis1',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_rename',\n",
       " '_replace_columnwise',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_series',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_item_frame_value',\n",
       " '_set_item_mgr',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isetitem',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_orc',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'to_xml',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5117c1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58509, 49)\n"
     ]
    }
   ],
   "source": [
    "#DataSet Dimensions\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c3fdc",
   "metadata": {},
   "source": [
    "## Preparing training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a13dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate features and target\n",
    "#La variable X contient toutes les colonnes sauf la dernière de la dataframe \"data\". Cela correspond aux caractéristiques ou variables d'entrée du modèle.\n",
    "X = data.iloc[:, :-1]\n",
    "\n",
    "#La variable Y contient la dernière colonne de la dataframe \"data\", qui représente la cible ou la variable à prédire.\n",
    "Y = data.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Normalisation des données caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "## Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "#Cela spécifie que 20% des données seront utilisées comme ensemble de test, tandis que 80% seront utilisées comme ensemble d'entraînement.\n",
    "#La division des données se fera de la même manière dans chaque execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87feba0d",
   "metadata": {},
   "source": [
    "##  Evaluate the model (MSE, Execution time) considering default parameters\n",
    "\n",
    "### Paramètres de l’algorithme SVM\n",
    "les principaux paramètres de l'algorithme svm sont: \n",
    "- C (pénalité de régularisation): contrôle le compromis entre la marge d'erreur et la classification correcte des données d'entraînement.\n",
    "- kernel (noyau): Le choix du noyau détermine comment les données sont transformées pour permettre une séparation non linéaire. \n",
    "- gamma: influence la forme de la frontière de décision. Une valeur plus élevée de gamma indique que les points doivent être très proches les uns des autres pour être considérés comme une classe. \n",
    "\n",
    "### Paramètres par défaut\n",
    "- C (pénalité de régularisation) : La valeur par défaut est 1.0. \n",
    "- kernel (noyau) : La valeur par défaut est 'rbf' (Radial Basis Function).\n",
    "- gamma : La valeur par défaut est 'scale'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a7b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Create and train the SVM model\n",
    "start_time = time.time()\n",
    "model = SVC()\n",
    "model.fit(X_train, Y_train)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0cede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 91.0583713054657 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate the execution time\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51936837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  1  2 ...  3  7 10]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions_ = model.predict(X_test)\n",
    "print(predictions_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8621100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE :  0.6936355673296729\n",
      "Testing MSE :  0.9741069902580756\n"
     ]
    }
   ],
   "source": [
    "# calculer l'erreur quadratique moyenne entre les vraies étiquettes de classe et les prédictions sur l'ensemble de test.\n",
    "train_mse = mean_squared_error(Y_train, model.predict(X_train))\n",
    "test_mse = mean_squared_error(Y_test, model.predict(X_test))\n",
    "\n",
    "print(\"Training MSE : \", train_mse)\n",
    "print(\"Testing MSE : \", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e02e4e",
   "metadata": {},
   "source": [
    "> le MSE sur l'ensemble de test est nettement plus élevé que le MSE sur l'ensemble d'entraînement, cela peut indiquer un problème de surapprentissage, où le modèle est trop spécifique aux données d'entraînement et ne se généralise pas bien aux nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54e8a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9631686891129722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the training accuracy\n",
    "test_accuracy = accuracy_score(Y_test, predictions_)\n",
    "print(\"Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796df433",
   "metadata": {},
   "source": [
    "##  Evaluate the model (MSE, RMSE, Execution time) considering optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b6564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': [0.1, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "668aa9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(\"Number of CPU cores:\", num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba554caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search is executing...\n",
      "Best parameters:  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Perform grid search cross-validation\n",
    "#Déterminer les paramètres optimaux\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=num_cores)\n",
    "print(\"Grid search is executing...\")\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93d0676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réentraîner le modèle avec les meilleurs paramètres sur l'ensemble des données d'entraînement\n",
    "start_time_optimal = time.time()\n",
    "best_model = SVC(**grid_search.best_params_)\n",
    "best_model.fit(X_train, Y_train)\n",
    "end_time_optimal = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15f2c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time with optimal parameters: 80.3690915107727 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate the execution time with optimal parameters\n",
    "execution_time = end_time_optimal - start_time_optimal\n",
    "print(\"Execution time with optimal parameters:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f65031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE :  0.0005341081462174461\n",
      "Testing MSE :  1.0502478208853188\n"
     ]
    }
   ],
   "source": [
    "# Calculate training and testing MSE for optimal parameters\n",
    "train_mse = mean_squared_error(Y_train, best_model.predict(X_train))\n",
    "test_mse = mean_squared_error(Y_test, best_model.predict(X_test))\n",
    "\n",
    "print(\"Training MSE : \", train_mse)\n",
    "print(\"Testing MSE : \", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b369eecd",
   "metadata": {},
   "source": [
    "> Concernant le training MSE:\n",
    "Dans le cas des paramètres par défaut, une erreur relativement élevée sur les données d'entraînement est obtenu.\n",
    "Avec les paramètres optimaux, la valeur a considérablement diminué pour atteindre 0.0005, ce qui indique une meilleure adéquation du modèle aux données d'entraînement. Cela suggère que le modèle est capable de capturer les relations entre les caractéristiques d'entrée et les étiquettes de sortie de manière plus précise.\n",
    "> Concernant le testing MSE:\n",
    "La valeur a augmenté; Le modèle avec les paramètres optimaux est peut-être moins susceptible de surajuster les données d'entraînement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2872dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  1  2 ...  3  7 10]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0814dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with optimal parameters: 0.9709451375833191\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "#Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)\n",
    "accuracy_opt = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy with optimal parameters:\", accuracy_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24b98b",
   "metadata": {},
   "source": [
    "On constate une légère augmentation de la précision du modèle SVM, et donc une meilleure généralisation du modèle sur les données de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3250d4e",
   "metadata": {},
   "source": [
    "# Comparison between SVM and RN\n",
    "- Temps d'exécution: le SVM est plus rapide pour entrainer que le RN.\n",
    "- Le RN a une mielleure précision que le SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e37d4",
   "metadata": {},
   "source": [
    "# LASSO et RIDGE\n",
    "Lasso et Ridge sont des techniques de régularisation utilisées avec SVM (Support Vector Machines) pour réduire le surapprentissage (overfitting) et améliorer la performance du modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dcbf299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso time  142.8544762134552\n",
      "Ridge time  230.92606496810913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "######LASSO et RIDGE\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "#LinearSVC pour l'implémentation de SVM linéaire pour la classification\n",
    "#paramètre l1 pour effectuer la régulation Lasso (L1 Regularization)\n",
    "svm_lasso = LinearSVC(penalty='l1', dual=False,C=0.1)\n",
    "svm_lasso.fit(X_train, Y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "#Temps pour entrainer le SVM avec la régularisation Lasso (L1) \n",
    "print(\"Lasso time \", end_time - start_time)\n",
    "#paramètre l2 pour effectuer la régulation Ridge (L2 Regularization)\n",
    "start_time2 = time.time()\n",
    "svm_ridge = LinearSVC(penalty='l2', dual=False,C=0.1)\n",
    "svm_ridge.fit(X_train, Y_train)\n",
    "end_time2 = time.time()\n",
    "\n",
    "#Temps pour entrainer le SVM avec la régularisation Ridge (L2)\n",
    "print(\"Ridge time \", end_time2 - start_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d49148b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE (Lasso): 0.6090798384856966\n",
      "Testing MSE (Lasso): 0.5804734233464365\n",
      "Training MSE (Ridge): 0.5895635268229111\n",
      "Testing MSE (Ridge): 0.5573662621774056\n"
     ]
    }
   ],
   "source": [
    "# Calcul du MSE pour le modèle Lasso\n",
    "y_train_pred_lasso = svm_lasso.predict(X_train)\n",
    "mse_train_lasso = mean_squared_error(Y_train, y_train_pred_lasso)\n",
    "print(\"Training MSE (Lasso):\", mse_train_lasso)\n",
    "\n",
    "y_test_pred_lasso = svm_lasso.predict(X_test)\n",
    "mse_test_lasso = mean_squared_error(Y_test, y_test_pred_lasso)\n",
    "print(\"Testing MSE (Lasso):\", mse_test_lasso)\n",
    "\n",
    "# Calcul du MSE pour le modèle Ridge\n",
    "y_train_pred_ridge = svm_ridge.predict(X_train)\n",
    "mse_train_ridge = mean_squared_error(Y_train, y_train_pred_ridge)\n",
    "print(\"Training MSE (Ridge):\", mse_train_ridge)\n",
    "\n",
    "y_test_pred_ridge = svm_ridge.predict(X_test)\n",
    "mse_test_ridge = mean_squared_error(Y_test, y_test_pred_ridge)\n",
    "print(\"Testing MSE (Ridge):\", mse_test_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85231c90",
   "metadata": {},
   "source": [
    "# Parallelization using Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b0ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08467fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialisation de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SVM Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start_time_with_spark = time.time()\n",
    "svm_with_spark = SVC()\n",
    "svm_with_spark.fit(X_train, Y_train)\n",
    "end_time_with_spark = time.time()\n",
    "\n",
    "# Arrêt de Spark\n",
    "spark.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4b333de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time avec Spark: 63.77378487586975 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate the execution time with spark apache\n",
    "execution_time_with_spark = end_time_with_spark - start_time_with_spark\n",
    "print(\"Execution time avec Spark:\", execution_time_with_spark, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e00af",
   "metadata": {},
   "source": [
    "On constate une dimunition du temps d'exécution en utilisant la parrallélisation avec spark. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
